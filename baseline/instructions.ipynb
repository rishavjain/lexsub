{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Stanford CoreNLP for dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SOURCE:- http://nlp.stanford.edu/software/nndep.shtml]\n",
    "\n",
    "Using the Stanford CoreNLP pipeline\n",
    "\n",
    "This parser is integrated into Stanford CoreNLP as a new annotator.\n",
    "\n",
    "If you want to use the transition-based parser from the command line, invoke StanfordCoreNLP with the depparse annotator. This annotator has dependencies on the tokenize, ssplit, and pos annotators. An example invocation follows (assuming CoreNLP is on your classpath): \n",
    "\n",
    "```\n",
    "java edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,depparse -file <INPUT_FILE>\n",
    "```\n",
    "\n",
    "The command does not work !\n",
    "\n",
    "The classpath need to be set.\n",
    "\n",
    "```\n",
    "java -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,depparse -file <INPUT_FILE>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating python script for dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating a config file\n",
    "```\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "print(config.sections())\n",
    "config['DEFAULT'] = {}\n",
    "config['DEFAULT']['BasePath'] = 'C:\\\\Users\\\\cop15rj\\\\PycharmProjects\\\\lexsub'\n",
    "print(config['DEFAULT']['BasePath'])\n",
    "\n",
    "with open('desktop.ini', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reading configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_path = C:\\Users\\cop15rj\\PycharmProjects\\lexsub\n",
      "parser_path = C:\\Users\\cop15rj\\PycharmProjects\\lexsub\\stanford-corenlp-full-2015-12-09\n",
      "parser_class = edu.stanford.nlp.pipeline.StanfordCoreNLP\n",
      "parser_annotators = tokenize,ssplit,pos,depparse\n",
      "parser_memory = 4\n",
      "java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,depparse -file ..\\corpus\\ukwac_subset_1M_untagged.txt -outputDirectory C:\\Users\\cop15rj\\PycharmProjects\\lexsub -outputFormat conll\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(), inline_comment_prefixes=('#',))\n",
    "config.read('desktop.ini')\n",
    "\n",
    "base_path = config['PATHS']['base_path']\n",
    "print('base_path', '=', config['PATHS']['base_path'])\n",
    "\n",
    "parser_path = config['PATHS']['parser_path']\n",
    "print('parser_path', '=', config['PATHS']['parser_path'])\n",
    "\n",
    "parser_class = config['PARSER']['class']\n",
    "print('parser_class', '=', config['PARSER']['class'])\n",
    "\n",
    "parser_annotators = config['PARSER']['annotators']\n",
    "print('parser_annotators', '=', config['PARSER']['annotators'])\n",
    "\n",
    "parser_memory = config['PARSER']['max_mem']\n",
    "print('parser_memory', '=', parser_memory)\n",
    "\n",
    "parser_cmdFmtStr = config['PARSER']['cmdFmtStr']\n",
    "\n",
    "in_file = '..\\\\corpus\\\\ukwac_subset_1M_untagged.txt'\n",
    "out_dir = base_path\n",
    "\n",
    "cmd = parser_cmdFmtStr.format(parser_memory, parser_path, parser_class, parser_annotators, in_file, out_dir)\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\\r\\n'\n",
      "b'[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\\r\\n'\n",
      "b'[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\\r\\n'\n",
      "b'[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\\r\\n'\n",
      "b'Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.7 sec].\\r\\n'\n",
      "b'[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\\r\\n'\n",
      "b'Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \\r\\n'\n",
      "b'PreComputed 100000, Elapsed Time: 1.622 (s)\\r\\n'\n",
      "b'Initializing dependency parser done [4.9 sec].\\r\\n'\n",
      "b'\\n'\n",
      "b'Processing file C:\\\\Users\\\\cop15rj\\\\PycharmProjects\\\\lexsub\\\\stanford-corenlp-full-2015-12-09\\\\..\\\\corpus\\\\ukwac_subset_1M_untagged.txt ... writing to C:\\\\Users\\\\cop15rj\\\\PycharmProjects\\\\lexsub\\\\ukwac_subset_1M_untagged.txt.conll\\n'\n",
      "b'Annotating file C:\\\\Users\\\\cop15rj\\\\PycharmProjects\\\\lexsub\\\\stanford-corenlp-full-2015-12-09\\\\..\\\\corpus\\\\ukwac_subset_1M_untagged.txt\\n'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "os.chdir(parser_path)\n",
    "parser_process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "for line in iter(parser_process.stdout.readline, ''):\n",
    "    print(line.decode(\"utf-8\"))\n",
    "    \n",
    "parser_process.stdout.close()\n",
    "parser_process.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
